{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r \"requirements.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import custom Agent library using LLama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Agents import Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load language model and initialize Agent\n",
    "\n",
    "- Agent 1 will be given the client address of where the model is located, a name, and a location to store it's documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from text_generation import Client\n",
    "\n",
    "load_dotenv()\n",
    "client_address = os.environ.get(\"CLIENT_ADDRESS\")\n",
    "client = Client(client_address)\n",
    "\n",
    "Agent_1 = Agent(client, \"Agent_1\", \"./agent_dbs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add documents of choice\n",
    "\n",
    "- For this example, I am adding a pdf of a wikipedia page on the \"Waluigi Effect\"\n",
    "- As of now, the system only accepts PDFs\n",
    "- The system takes the PDF, converts it to a txt for embeddings, and stores in it's databbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Successfully Uploaded.\n"
     ]
    }
   ],
   "source": [
    "Agent_1.add_to_db('./waluigi_effect_wikipedia.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we can call on Agent 1 for a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Waluigi Effect refers to the phenomenon where large language models (LLMs) produce negative or antagonistic responses, often opposite of what users were looking for, creating a potentially malignant alter ego.<|eot_id|>**Memory Bank Notes**\n",
      "\n",
      "**Topic:** The Waluigi Effect\n",
      "\n",
      "**Definition:** The Waluigi Effect refers to the phenomenon where Large Language Models (LLMs) produce negative or antagonistic responses, often opposite of what users were looking for, creating a potentially malignant alter ego.\n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "* The Waluigi Effect occurs in Large Language Models (LLMs)\n",
      "* It involves producing negative or antagonistic responses\n",
      "* These responses are often opposite of what users intended or expected\n",
      "* Can lead to the creation of a malignant alter ego\n",
      "\n",
      "**Relevance:** Understanding the Waluigi Effect is crucial for developers, users"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Agent_1: The Waluigi Effect refers to the phenomenon where large language models (LLMs) produce negative or antagonistic responses, often opposite of what users were looking for, creating a potentially malignant alter ego.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Agent_1.instruct(\"What is the Waluigi Effect?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To demonstrate the system is working effectively, let's view an Agent without a given PDF document.\n",
    "\n",
    "- We can notice the responses are much different. This is due to the fact that the document I used contains information that the language model was not previously trained on, therefore it does not know the answer based on it's knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Waluigi Effect refers to a phenomenon in game development where a character or feature is introduced as a parody or alternative to an existing one, but ends up becoming more popular or iconic than the original. Waluigi, a character from the Mario series, is often cited as the embodiment of this effect.<|eot_id|>**Memory Bank Notes**\n",
      "\n",
      "**Topic:** The Waluigi Effect\n",
      "\n",
      "**Definition:** A phenomenon in game development where a character or feature, introduced as a parody or alternative to an existing one, gains more popularity or iconic status than the original.\n",
      "\n",
      "**Origin:** Named after Waluigi, a character from the Mario series, who embodies this effect.\n",
      "\n",
      "**Key Takeaway:** The Waluigi Effect highlights how a parody or alternative can surpass the original in popularity, making it a significant concept in game development and character creation.\n",
      "\n",
      "**Future Reference:** This concept can be applied to understanding how characters or features evolve in games and how they may unexpectedly"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Agent_2: The Waluigi Effect refers to a phenomenon in game development where a character or feature is introduced as a parody or alternative to an existing one, but ends up becoming more popular or iconic than the original. Waluigi, a character from the Mario series, is often cited as the embodiment of this effect.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Agent_2 = Agent(client, \"Agent_2\", \"./agent_dbs\")\n",
    "\n",
    "Agent_2.instruct(\"What is the Waluigi Effect?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Agent Attributes\n",
    "- Lastly, let's look at the attributes of Agent 1. This will showcase the capabilities of Agents being able to store information for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Memory Bank Notes**\n",
      "\n",
      "**Topic:** The Waluigi Effect\n",
      "\n",
      "**Definition:** The Waluigi Effect refers to the phenomenon where Large Language Models (LLMs) produce negative or antagonistic responses, often opposite of what users were looking for, creating a potentially malignant alter ego.\n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "* The Waluigi Effect occurs in Large Language Models (LLMs)\n",
      "* It involves producing negative or antagonistic responses\n",
      "* These responses are often opposite of what users intended or expected\n",
      "* Can lead to the creation of a malignant alter ego\n",
      "\n",
      "**Relevance:** Understanding the Waluigi Effect is crucial for developers, users\n"
     ]
    }
   ],
   "source": [
    "# Here we will look into Agent 1's memory\n",
    "print(Agent_1.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We've been discussing the Waluigi Effect, which refers to the phenomenon where large language models produce negative or antagonistic responses, often opposite of what users were looking for, creating a potentially malignant alter ego.<|eot_id|>**Memory Bank Notes**\n",
      "\n",
      "**Topic:** The Waluigi Effect\n",
      "\n",
      "**Definition:** The Waluigi Effect refers to the phenomenon where large language models (LLMs) produce negative or antagonistic responses, often opposite of what users were looking for, creating a potentially malignant alter ego.\n",
      "\n",
      "**Key Takeaway:** The Waluigi Effect highlights the potential risk of LLMs generating harmful or opposing responses, which can be detrimental to user interactions.\n",
      "\n",
      "**Relevance:** This concept is crucial for language model developers, AI researchers, and users to be aware of, as it can impact the overall user experience and trust in AI systems.\n",
      "\n",
      "**Future"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Agent_1: We've been discussing the Waluigi Effect, which refers to the phenomenon where large language models produce negative or antagonistic responses, often opposite of what users were looking for, creating a potentially malignant alter ego.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we will call Agent_1 again to talk about what it knows so far.\n",
    "\n",
    "Agent_1.instruct(\"What have we been talking about so far?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
